# EU AI Act - High-Risk AI Systems

## Definition

High-risk AI systems are those that pose significant risks to health, safety, or fundamental rights of individuals. These systems are subject to strict compliance requirements and mandatory conformity assessment procedures.

## Categories of High-Risk AI Systems

### Critical Infrastructure
- AI systems used in the management and operation of road traffic and the supply of water, gas, heating, and electricity
- AI systems used in the management and operation of digital infrastructure
- AI systems used in the management and operation of transport infrastructure

### Education and Training
- AI systems used in education and training institutions for the purpose of assessing students
- AI systems used for the purpose of determining access to educational institutions
- AI systems used for the purpose of determining the admission or admission procedures to educational institutions

### Employment and Worker Management
- AI systems used for the purpose of recruitment or selection of natural persons
- AI systems used for the purpose of making decisions on promotion and termination of work-related contractual relationships
- AI systems used for the purpose of task allocation and monitoring and evaluation of performance and behavior of persons in work-related contractual relationships

### Essential Private and Public Services
- AI systems used for the purpose of evaluating the creditworthiness of natural persons
- AI systems used for the purpose of evaluating the creditworthiness of legal persons
- AI systems used for the purpose of evaluating the creditworthiness of natural persons or legal persons in connection with decisions on access to essential private services

### Law Enforcement
- AI systems used by law enforcement authorities for the purpose of the prevention, investigation, detection, or prosecution of criminal offenses
- AI systems used by law enforcement authorities for the purpose of the execution of criminal penalties
- AI systems used by law enforcement authorities for the purpose of the prevention, investigation, detection, or prosecution of administrative offenses

### Migration and Border Control
- AI systems used for the purpose of the prevention, investigation, detection, or prosecution of administrative offenses in the field of migration, asylum, and border control
- AI systems used for the purpose of the prevention, investigation, detection, or prosecution of criminal offenses in the field of migration, asylum, and border control

### Administration of Justice
- AI systems used by courts and administrative authorities for the purpose of the prevention, investigation, detection, or prosecution of criminal offenses
- AI systems used by courts and administrative authorities for the purpose of the execution of criminal penalties
- AI systems used by courts and administrative authorities for the purpose of the prevention, investigation, detection, or prosecution of administrative offenses

## Compliance Requirements

### Risk Management System
- Continuous risk assessment and mitigation
- Documentation of risk management measures
- Regular review and update of risk management system
- Integration of risk management into quality management system

### Data Governance
- Training, validation, and testing data must be relevant, representative, and free of errors
- Data governance and management practices must be documented
- Data quality and integrity must be ensured throughout the AI system lifecycle

### Technical Documentation
- Comprehensive technical documentation required
- Documentation must be kept up to date
- Documentation must be made available to competent authorities
- Documentation must include system architecture, data sources, and algorithms

### Record Keeping
- Automatic logging capabilities required
- Logs must be kept for at least 6 months
- Logs must be made available to competent authorities
- Logs must include system inputs, outputs, and decisions

### Transparency and Provision of Information
- Users must be informed that they are interacting with an AI system
- Users must be provided with information about the AI system's capabilities and limitations
- Users must be informed about their rights and remedies

### Human Oversight
- Human oversight must be ensured throughout the AI system lifecycle
- Human oversight must be effective and meaningful
- Human oversight must be documented and traceable
- Human oversight must be appropriate to the risks posed by the AI system

### Accuracy, Robustness, and Cybersecurity
- AI systems must be accurate and robust
- AI systems must be secure against attacks
- AI systems must be resilient to errors and failures
- AI systems must be tested and validated before deployment

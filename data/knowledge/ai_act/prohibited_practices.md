# EU AI Act - Prohibited AI Practices

## Overview

The EU AI Act explicitly prohibits certain AI practices that are considered to pose unacceptable risks to fundamental rights and democratic values. These practices are banned outright and cannot be used under any circumstances.

## Prohibited AI Practices

### 1. AI Systems that Manipulate Human Behavior

**Definition**: AI systems that deploy subliminal techniques beyond a person's consciousness to materially distort a person's behavior in a manner that causes or is likely to cause that person or another person physical or psychological harm.

**Examples**:
- AI systems that use subliminal messaging to influence purchasing decisions
- AI systems that manipulate emotions to drive engagement
- AI systems that exploit psychological vulnerabilities to influence behavior

**Prohibition**: These systems are completely banned and cannot be developed, deployed, or used.

### 2. AI Systems that Exploit Vulnerabilities

**Definition**: AI systems that exploit the vulnerabilities of a specific group of persons due to their age, physical or mental disability, or specific social or economic situation to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm.

**Examples**:
- AI systems that exploit children's cognitive limitations
- AI systems that target elderly persons with cognitive impairments
- AI systems that exploit persons with mental disabilities
- AI systems that exploit persons in vulnerable economic situations

**Prohibition**: These systems are completely banned and cannot be developed, deployed, or used.

### 3. AI Systems that Create Social Scoring

**Definition**: AI systems that evaluate or classify natural persons or groups thereof over a certain period of time based on their social behavior or known or predicted personal or personality characteristics, status, or social connections, and that assign a score or classification to them that is used to determine their access to essential private and public services.

**Examples**:
- AI systems that score individuals based on their social media activity
- AI systems that classify persons based on their political views
- AI systems that assign scores based on personal relationships
- AI systems that evaluate persons based on their lifestyle choices

**Prohibition**: These systems are completely banned and cannot be developed, deployed, or used.

### 4. AI Systems that Create Biometric Categorization

**Definition**: AI systems that categorize natural persons based on their biometric data to infer or predict their race, political opinions, trade union membership, religious or philosophical beliefs, sex life, or sexual orientation, unless the use is strictly necessary for the performance of a task carried out in the public interest by a competent authority.

**Examples**:
- AI systems that categorize persons by race using facial recognition
- AI systems that predict political views from biometric data
- AI systems that infer sexual orientation from biometric characteristics
- AI systems that categorize persons by religious beliefs using biometric data

**Prohibition**: These systems are completely banned and cannot be developed, deployed, or used.

## Exceptions and Derogations

### Law Enforcement Exceptions
- Limited exceptions for law enforcement purposes
- Strict conditions and safeguards required
- Authorization by competent authority necessary
- Regular review and oversight required

### National Security Exceptions
- Limited exceptions for national security purposes
- Strict conditions and safeguards required
- Authorization by competent authority necessary
- Regular review and oversight required

### Research and Development Exceptions
- Limited exceptions for research and development purposes
- Strict conditions and safeguards required
- Authorization by competent authority necessary
- Regular review and oversight required

## Enforcement and Penalties

### Administrative Fines
- Up to â‚¬30 million or 6% of annual worldwide turnover
- Whichever is higher
- Fines are calculated based on the severity of the violation
- Fines are imposed by competent authorities

### Criminal Penalties
- Criminal penalties for serious violations
- Imprisonment for up to 5 years
- Criminal penalties are imposed by competent authorities
- Criminal penalties are in addition to administrative fines

### Compliance Measures
- Mandatory compliance programs
- Regular audits and assessments
- Training and awareness programs
- Documentation and record-keeping requirements

## Compliance Requirements

### Due Diligence
- Organizations must conduct due diligence before deploying AI systems
- Organizations must assess whether their AI systems fall under prohibited practices
- Organizations must implement appropriate safeguards and controls
- Organizations must document their compliance measures

### Risk Assessment
- Organizations must assess the risks posed by their AI systems
- Organizations must implement appropriate risk mitigation measures
- Organizations must regularly review and update their risk assessments
- Organizations must document their risk assessment processes

### Monitoring and Oversight
- Organizations must monitor their AI systems for compliance
- Organizations must implement appropriate oversight mechanisms
- Organizations must regularly review and update their monitoring systems
- Organizations must document their monitoring and oversight processes
